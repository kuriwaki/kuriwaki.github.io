---
layout: bio-sidebar
title: "Shiro Kuriwaki"
---

<div class="wrapper">
  <section>
    {% include_cached masthead.html %}
    <div align="left">
      <img src="images/kuriwaki_swing-split_hD.png" alt="swing-D" height="160" width="750">
      <img src="images/kuriwaki_swing-split_hR.png" alt="swing-R" height="160" width="750">
    </div>


      <div align="left">
        <h3 id="pubs">Peer-Reviewed Publications</h3>
      </div>
      <div align="left">
        <h4>American Politics</h4>
      </div>
      <p>
        <ul class="dashed">
          <li><a href="https://cces.gov.harvard.edu/files/cces/files/AnsolabehereKuriwaki_AJPS.pdf"> Congressional Representation: Accountability from the Constituent’s Perspective.</a> (with Stephen Ansolabehere). <b><i>American Journal of Political Science</i></b>. [Summarized in the <a href="https://ajps.org/2021/07/26/congressional-representation-accountability-from-the-constituents-perspective/">AJPS Blog</a>] [<a href="https://doi.org/10.7910/DVN/QOVWMM">Data</a>]</li>
          <details>
            <summary>Abstract</summary>
            The premise that constituents hold representatives accountable for their legislative decisions undergirds political theories of democracy and legal theories of statutory interpretation. But studies of this at the individual level are rare, examine only a handful of issues, and arrive at mixed results. We provide an extensive assessment of issue accountability at the individual level. We trace the congressional rollcall votes on 44 bills across seven Congresses (2006-2018), and link them to constituent's perceptions of their representative's votes and their evaluation of their representative.  Correlational, instrumental variables, and experimental approaches all show that constituents hold representatives accountable. A one-standard deviation increase in a constituent's perceived issue agreement with their representative can improve net approval by 35 percentage points.  Congressional districts, however, are heterogeneous. Consequently, the effect of issue agreement on vote is much smaller at the district-level, resolving an apparent discrepancy between micro and macro studies.
          </details>
          <li><a href="https://doi.org/10.1017/S0003055419000170">Wealth, Slave Ownership, and Fighting for the Confederacy: An Empirical Study of the American Civil War.</a>  (with Andrew B. Hall and Connor Huff). <b><i>American Political Science Review</i></b>, vol. 113, p. 658-673. 2019. [Covered by <a
            href="https://www.iheart.com/podcast/8-voxs-the-weeds-27868384/episode/building-the-trump-state-43587864/">The Weeds</a> podcast] [<a href="https://doi.org/10.7910/DVN/RRBPUD">Data</a>]</li>
            <details><summary>Abstract</summary>
              How did personal wealth and slaveownership affect the likelihood Southerners fought for the Confederate Army in the American Civil War? On the one hand, wealthy Southerners had incentives to free-ride on poorer Southerners and avoid fighting; on the other hand, wealthy Southerners were disproportionately slaveowners, and thus had more at stake in the outcome of the war. We assemble a dataset on roughly 3.9 million free citizens in the Confederacy and show that slaveowners were more likely to fight than non-slaveowners. We then exploit a randomized land lottery held in 1832 in Georgia. Households of lottery winners owned more slaves in 1850 and were more likely to have sons who fought in the Confederate Army. We conclude that slaveownership, in contrast to some other kinds of wealth, compelled Southerners to fight despite free-rider incentives because it raised their stakes in the war’s outcome.
            </details>
          </ul>
        </p>
        <div align="left">
          <h4>Survey Statistics and Demography</h4>
        </div>
        <p>
          <ul class="dashed">
            <li><a href="https://www.nature.com/articles/s41586-021-04198-4">Unrepresentative Big Surveys Significantly Overestimated US Vaccine Uptake.</a> (with Valerie C. Bradley, Michael Isakov, Dino Sejdinovic, Xiao-Li Meng, and Seth Flaxman). <i><b>Nature</b></i>, vol. 600, p. 695-700. 2021. [Covered by <a href="https://news.harvard.edu/gazette/story/2021/12/vaccination-surveys-fell-victim-to-big-data-paradox-harvard-researchers-say/">Harvard Gazette</a>] [<a href="https://github.com/vcbradley/ddc-vaccine-US">Data</a>]</li>
                <details><summary>Abstract</summary>
                      Surveys are a crucial tool for understanding public opinion and behaviour, and their accuracy depends on maintaining statistical representativeness of their target populations by minimizing biases from all sources. Increasing data size shrinks confidence intervals but magnifies the effect of survey bias: an instance of the Big Data Paradox. Here we demonstrate this paradox in estimates of first-dose COVID-19 vaccine uptake in US adults from 9 January to 19 May 2021 from two large surveys: Delphi–Facebook (about 250,000 responses per week) and Census Household Pulse (about 75,000 every two weeks). In May 2021, Delphi–Facebook overestimated uptake by 17 percentage points (14–20 percentage points with 5% benchmark imprecision) and Census Household Pulse by 14 (11–17 percentage points with 5% benchmark imprecision), compared to a retroactively updated benchmark the Centers for Disease Control and Prevention published on 26 May 2021. Moreover, their large sample sizes led to miniscule margins of error on the incorrect estimates. By contrast, an Axios–Ipsos online panel with about 1,000 responses per week following survey research best practices provided reliable estimates and uncertainty quantification. We decompose observed error using a recent analytic framework to explain the inaccuracy in the three surveys. We then analyse the implications for vaccine hesitancy and willingness. We show how a survey of 250,000 respondents can produce an estimate of the population mean that is no more accurate than an estimate from a simple random sample of size 10. Our central message is that data quality matters more than data quantity, and that compensating the former with the latter is a mathematically provable losing proposition.
                </details>
             <li><a href= "https://www.science.org/doi/10.1126/sciadv.abk3283">The Use of Differential Privacy for Census Data and its Impact on Redistricting: The Case of the 2020 U.S. Census.</a> (with Chris Kenny, Cory McCartan, Evan Rosenman, Tyler Simko, and Kosuke Imai). <b><i>Science Advances</i></b>, vol. 7, eabk3283. 2021.  Originally a Public Comment to the Census Bureau (May 28, 2021). [<a href="https://alarm-redist.github.io/posts/2021-06-02-das-evaluation-faq/">FAQ</a>, <a href="https://alarm-redist.github.io/posts/2021-06-09-dsep-decision-response/">Reaction to the Bureau's Response (June 9, 2021)</a>.] [<a href="https://doi.org/10.7910/DVN/TNNSXG">Data</a>]</li>
                <details><summary>Abstract</summary>
                    Census statistics play a key role in public policy decisions and social science research. Yet given the risk of revealing individual information, many statistical agencies are considering disclosure control methods based on differential privacy, which add noise to tabulated data. Unlike other applications of differential privacy, however, census statistics must be post-processed after noise injection to be usable. We study the impact of the US Census Bureau's new Disclosure Avoidance System (DAS) on a major application of census statistics: the redrawing of electoral districts. We find that the DAS systematically undercounts the population in mixed-race and mixed-partisan precincts, yielding unpredictable racial and partisan biases. The DAS also leads to a likely violation of "One Person, One Vote" standard as currently interpreted, but does not prevent accurate predictions of an individual's race and ethnicity. Our findings underscore the difficulty of balancing accuracy and respondent privacy in the Census.
                    </details>
                <details><summary>Selected Press Coverage</summary>
                  Covered by  <a href="https://apnews.com/article/business-census-2020-technology-e701e313e841674be6396321343b7e49"><i>AP News</i></a>, <a href="https://www.washingtonpost.com/local/social-issues/2020-census-differential-privacy-ipums/2021/06/01/6c94b46e-c30d-11eb-93f5-ee9558eecf4b_story.html"><i>Washington Post</i></a>, <a href="https://www.thecrimson.com/article/2021/6/16/researchers-identify-concerns-census-bureau/"><i>The Harvard Crimson</i></a>, <a href="https://www.sfchronicle.com/us-world/article/The-most-detailed-data-about-the-US-population-in-16378154.php"><i>San Francisco Chronicle</i></a>, <a href="https://www.slowboring.com/p/census-privacy"><i>Matthew Yglesias blog</i></a>, Statistical Modeling (Andrew Gelman's blog) by Jessica Hullman (<a href="https://statmodeling.stat.columbia.edu/2021/10/20/how-does-post-processed-differentially-private-census-data-affect-redistricting-how-concerned-should-we-be-about-gerrymandering-with-the-new-das/">Part 1</a>, <a href="https://statmodeling.stat.columbia.edu/2021/10/27/is-the-accuracy-of-bayesian-improved-surname-geocoding-bad-news-for-privacy-protection-at-the-census-technically-no-pr-wise-probably/">Part 2</a>)
                </details>
            <li><a href="https://hdsr.mitpress.mit.edu/pub/cnxbwum6">Towards Principled Unskewing: Viewing 2020 Election Polls Through a Corrective Lens from 2016.</a> (with Michael Isakov). <b><i>Harvard Data Science Review</i></b>, vol. 2.4 (pre - 2020 election issue). 2020. [Covered by <a href="https://www.thecrimson.com/article/2020/11/2/2016-election-polls-kuriwaki-isakov/"> <i>The Harvard Crimson</i></a>] [<a href="https://osf.io/29pvm/">PDF version</a>  with post-election review] [<a href="https://codeocean.com/capsule/1721560/tree/v1">Data</a>] </li>
              <details><summary>Abstract</summary>
                We apply the concept of the data defect index (Meng, 2018) to study the potential impact of systematic errors on the 2020 pre-election polls in twelve Presidential battleground states. We investigate the impact under the hypothetical scenarios that (1) the magnitude of the underlying non-responses bias correlated with supporting Donald Trump is similar to that of the 2016 polls, (2) the pollsters' ability to correct systematic errors via weighting has not improved significantly, and (3) turnout levels remain similar as 2016. Because survey weights are crucial for our investigations but are often not released, we adopt two approximate methods under different modeling assumptions. Under these scenarios, which may be far from reality, our models shift Trump's estimated two-party voteshare by a percentage point in his favor in the median battleground state, and increases twofold the uncertainty around the voteshare estimate.
              </details>
            </ul>
          </p>
          <h4>Education in Political Science</h4>
          <p>
            <ul class="dashed">
              <li><a href="https://gking.harvard.edu/files/gking/files/prefresher.pdf"> The "Math Prefresher" and The Collective Future of Political Science Graduate Training. </a> (with Gary King and Yon Soo Park). <b><i>PS: Political Science and Politics</i></b>, vol. 54, p. 537-541. 2020. </li>
              <details><summary>Abstract</summary>
                The political science math prefresher arose a quarter-century ago and has now spread to many of our discipline’s PhD programs. Incoming students arrive for graduate school a few weeks early for ungraded instruction in math, statistics, and computer science  as  they  relate  to  political  science.  The  prefresher’s  benefits,  however,  go  beyond  its  technical content: it opens pathways to mastering methods necessary for political science research, facilitates connections among peers, and &mdash; perhaps most important &mdash; eases the transition to the increasingly collaborative nature of graduate work. The prefresher also shows how faculty across a highly diverse discipline have worked together to train the next generation. We review this program and advance its collaborative aspects by building infrastructure to share teaching content across universities so that separate programs can build on one another’s work and improve all of our programs.</details>
              </ul>
            </p>


            <div align="left">
              <h3 id="wp">Selected Working Papers</h3>
            </div>
            <p>
              <ul class="dashed">
                <li> <b><a href="https://osf.io/preprints/socarxiv/bvgz3/">Ticket Splitting in a Nationalized Era</a>. </b>
             [Previously titled "Party Loyalty on the Long Ballot: Is Ticket Splitting More Prevalent in State and Local Elections?]. [Covered by  <a href="https://perma.cc/V83G-X9US"><i>The Post and Courier</i></a>, <a href="https://perma.cc/L4AV-2SWG "><i>Governing</i>, <a href="https://perma.cc/PH22-GDS7"><i>Colorado Public Radio News</i></a>].</li>
             <details><summary>Abstract</summary>
            <p>Many believe that party loyalty in U.S. elections has reached heights unprecedented in the post-war era, although this finding relies on evidence from presidential, congressional, and gubernatorial elections. If party labels are a heuristic, we would expect  party-line voting to be even more dominant in lower-information elections. Yet, here I show that the prevalence of ticket splitting in state and local offices is often similar to or higher than in national offices because of larger incumbency advantages and starker candidate valence differentials. Because neither surveys nor election returns have been able to reliably measure individual vote choice in downballot races, I introduce an underused source of voter data: cast vote records. I create a database from voting machines that reveals the vote choices of 6.6 million voters for all offices on the long ballot, and I design a clustering algorithm tailored to such ballot data. In contrast to ticket splitting rates of 5 to 7 percent in U.S. House races, about 15 to 20 percent of voters split their ticket in a modal Sheriff race. Even in a nationalized politics, a fraction of voters still cross party lines to vote for the more experienced candidate in state and local elections.</p>
          </details>
                <li><a href="https://arxiv.org/abs/2105.05829">Synthetic Area Weighting for Measuring Public Opinion in Small Areas</a> (with Soichiro Yamauchi). [<a href ="papers/kuriwaki_syntharea_handout.pdf">Slides</a> from Polmeth]</li>
                <details><summary>Abstract</summary>
                  The comparison of subnational areas is ubiquitous but survey samples of these areas are often biased or prohibitively small.  Researchers turn to methods such as multilevel regression and poststratiﬁcation (MRP) to improve the efficiency of estimates by partially pooling data across areas via random effects.  However, the random effect approach can pool observations only through area-level aggregates.
                  We instead propose a weighting estimator, the <i>synthetic area estimator</i>, which weights on variables measured only in the survey to partially pool observations <i>individually</i>. The proposed method consists of two-step weighting: first to adjust differences across areas and then to adjust for differences between the sample and population. Unlike MRP, our estimator can directly use the national weights that are often estimated from pollsters using proprietary information. Our approach also clarifies the assumptions needed for valid partial pooling, without imposing an outcome model. We apply the proposed method to estimate the support for immigration policies at the congressional district level in Florida. Our empirical results show that small area estimation models with insufficient covariates can mask opinion heterogeneities across districts.
                </details>
                <li><a href="https://doi.org/10.31219/osf.io/v3rhz">A Clustering Approach for Characterizing Voter Types: An Application to High-Dimensional Ballot and Survey Data</a></li>
                <details><summary>Abstract</summary>
                  Large-scale ballot and survey data hold the potential to uncover the prevalence of swing voters and strong partisans in the electorate. However, existing approaches either employ exploratory analyses that fail to fully leverage the information available in high-dimensional data, or impose a one-dimensional spatial voting model. I derive a clustering algorithm which better captures the probabilistic way in which theories of political behavior conceptualize the swing voter. Building from the canonical finite mixture model, I tailor the model to vote data, for example by allowing uncontested races. I apply this algorithm to actual ballots in the Florida 2000 election and a multi-state survey in 2018. In Palm Beach County, I find that up to 60 percent of voters were straight ticket voters; in the 2018 survey, even higher. The remaining groups of the electorate were likely to cross the party line and split their ticket, but not monolithically: swing voters were more likely to swing for state and local candidates and popular incumbents.
                </details>
                <li><a href="https://scholar.harvard.edu/files/dtingley/files/sparsemultilevel.pdf">Sparse Multilevel Regression (and Poststratification).</a> (with Max Goplerud, Marc Ratkovic, and Dustin Tingley).</li>
                <details><summary>Abstract</summary>
                  Multilevel models have long played an important role in a variety of social sciences.  We extend this framework by bringing to bear recent developments in the machine learning literature to allow for considerable flexibility.  We introduce a sparse regression framework that covers both  the  linear  case  as  well  as  a  logit  model  for  binary  outcome  data.   We  leverage  recent computational tricks based on data-augmentation to dramatically speed up estimation times with equal or better performance compared to existing approaches.  We apply our model in the context of multilevel modelling with post-stratification which has become a common tool for survey researchers.
                </details>
                <li> The Seats Votes Curve for Issues: On the Aggregation of Issue Preferences. (with Stephen Ansolabehere)</li>
                <details><summary>Abstract</summary>
                  The seats-votes curve is widely used to evaluate the fairness of electoral systems. Existing examples almost exclusively use election results to estimate the seats-votes curve. Instead of evaluating how votes for political parties translate into seats, we measure how the support for a particular policy translates into the proportion of districts whose majorities support that same policy, providing a similarly powerful measure of how an electoral system represents voter’s issue preferences. Using the twelve years of the Cooperative Congressional Election Study, we show the seats-votes curve equivalent for 75 key roll-call votes. We find that the seats-votes curve for issue preferences is remarkably majoritarian in both U.S. states and congressional districts, following the cubic polynomial. These findings suggest the blame for representational failures of Congress, in which issues with majority support do not become law, do not solely lie in the districting system.
                </details>
              </ul>
            </p>

            <div align = "left">
              <h3 id="diss">Dissertation </h3>
            </div>
            <p>
              <ul class = "dashed">
                <li> <a href="https://dash.harvard.edu/handle/1/37368520">The Swing Voter Paradox: Electoral Politics in a Nationalized Era.</a> Ph.D. Dissertation, Harvard University.</li>
              </ul>
            </p>

            <h3 id="book">Book Project: <i>Congressional Representation</i></h3>

            <p>(with Stephen Ansolabehere)</p>

            This book, tentatively titled <i>Congressional Representation</i>, argues that through all of the gridlock and the polarization that has plagued the government over the past three decades, the U.S. Congress remains a largely majoritarian institution.  Congress acts in line with the majority of people more often than not.  Building on 15 years of data on public preferences of more than 500,000 Americans, this study examines what voters know, what they care about when they vote, and how well their legislators and their Congress reflect their preferences.  Representation is not a seamless or mechanical process, but it aggregates peoples' beliefs and preferences well on the important issues that face the country.  Individual voters do not follow the details of congressional legislation but most know enough to hold correct beliefs about legislation and to hold their representatives accountable.  For their part, legislators are highly responsive to the aggregate opinion of their districts.   And, on important bills, Congress makes decisions in line with the majority of the nation.  When representation fails, it is often the obstruction of one branch of government or one party.
            <p>



              <div align="left">
                <h3 id="teaching">Teaching</h3>
              </div>

              <p>
                I have taught classes on American Politics, Japanese Politics, statistics, and programming, at the undergraduate, Masters, and PhD level. I received the 2020 <a href="https://www.hks.harvard.edu/more/events/honoring-class-2020/class-day-awards">Dean's Excellence in Teaching Award</a> at the Harvard Kennedy School of Public Policy for my teaching in econometrics and shepherding the use of the R statistical language in its core statistics sequence. This work included creating portable <a href="screencasts">screencasts of R workflows</a>, covering common topics in econometrics, causal inference, data science, quantitative social science.
              </p>


              <p>
                I am a <a href="https://education.rstudio.com/trainers/">RStudio certified trainer</a>, and have created several resources for statistics and data science for the social sciences that I hope are useful for other students and instructors. These include a workshop I co-designed on <a href="teacher-training">training teachers</a> in the social sciences for teaching statistics and programming  my presentations on  <a
                href="https://vimeo.com/channels/1591675">project-oriented workflow</a> (invited presentation, Toronto Data Workshop), introduction to <a href="programming/kuriwaki_github_handout.pdf">version control with GitHub</a> (<a
                href="https://github.com/kuriwaki/github-demo">source</a>), introduction to <a href="https://www.shirokuriwaki.com/programming/api201z_stata.html">Stata</a> (<a href="https://github.com/kuriwaki/stata-notes">source</a>), and statistics notes
                covering <a href="https://github.com/kuriwaki/stats-notes/raw/master/01_probability.pdf">Probability</a>, <a href="https://github.com/kuriwaki/stats-notes/raw/master/02_inference.pdf">Inference</a>, and <a
                href="https://github.com/kuriwaki/stats-notes/raw/master/03_regression.pdf">Regression</a> written for a Masters-level statistics course (<a href="https://github.com/kuriwaki/stats-notes">source</a>).
              </p>

              <p>
                On teaching writing, I edited Susan T. Fiske's writing advice: "<a href="https://doi.org/10.31234/osf.io/n32qw">Words to the Wise on Writing Scientific Papers</a>" (Fiske and Kuriwaki, 2021). 
              </p>



              <div align="left">
                <h3 id="datasets">Datasets</h3>
              </div>
              <p>
                <ul class="dashed">
                  <li> The <b>Cast Vote Records</b> project is collecting and organizing public ballot image logs to advance the understanding of voting patterns in federal, state and local elections. One of the project's goals is to establish a relational database for such data. This project is one of the 2018 <a href="http://electionlab.mit.edu/node/75">New Initiative Grants</a> from the MIT Election Data and Science Lab. Please feel free to contact me for any questions about this project. Fore more information, see the associated <a href="https://doi.org/10.31235/osf.io/bvgz3">empirical paper</a> or the memo on the <a href="https://osf.io/epwqx/">election administration</a> of cast vote records.</li>
                  <li> The <a href="https://doi.org/10.7910/DVN/II2DB6">Cumulative CCES Common Content (2006-2021)</a> (downloaded on Dataverse over 13,000 times) is a part of the Cooperative Congressional Election Survey Dataverse. It combines all common content respondents of the CCES and harmonizes key variables, so that researchers can analyze all years of the CCES or merge in standardized variables with their own CCES datasets.</li>
                  <li> The <a href="https://doi.org/10.7910/DVN/DGDRDT">Candidates in American General Elections</a> dataset (with Jeremiah Cha and James M. Snyder, Jr.) is a comprehensive list of winning and losing candidates in U.S. Congressional, Presidential, and Gubernatorial elections. Unlike official records or other datasets, we standardize candidate names acorss time and office, and record the incumbency of the candidates.</li>
                  <li> <a href="https://www.shirokuriwaki.com/ccesMRPprep/">Portable Routines for Preparing CCES and ACS data for MRP (<tt>ccesMRPprep</tt>)</a> is a set of datasets and API interfaces to facilitate Multilevel Regression Poststratification (MRP), a survey weighting method for small area estimation.  Other articles already provide helpful tutorials and code for MRP. But implementing a MRP entails considerable upfront costs related to data  collection, cleaning, and standardization. This package provides these routines: not only modeling software, but code to import and standardize publicly available data sources, combined with detailed documentation about these data sources. </li>
                  </ul>
                </p>

                <hr>

                <p><small>
                  <b>About the banner image:</b> Survey data from the <a href="https://doi.org/10.7910/DVN/II2DB6">Cumulative CCES</a>, limited to validated voters in contested districts who voted for a major party in the Presidency and House. Estimates are
                  made at the congressional district level and use Multilevel Regression Poststratification (<a href="https://www.shirokuriwaki.com/ccesMRPprep/">MRP</a>) stratifying on age, gender, education from the ACS and using House candidate incumbency
                  status and presidential voteshare as district-level predictors. In presidential years the values represent ticket splitting (e.g. Trump voters who voted for a 2016 Democratic House candidate); in midterm years they represent party switch from
                  the previous presidential election (e.g. Trump voters who voted for a 2018 Democratic House candidate). Districts where a Democrat and Republican candidate did not contest the general election are left blank. <i>Figure created by Shiro
                    Kuriwaki.</i>
                  </small></p>
                  <p><small>
                    <b>About this website:</b> This website uses code from <a href="https://github.com/mmistakes/minimal-mistakes">Minimal Mistakes</a>, Github Pages, uses some CSS from Matt Blackwell's website at the time, and is inspired by Sarah Bouchat's <a
                    href="https://bouchat.github.io/">website</a> and Andrew Hall's <a href="http://www.andrewbenjaminhall.com/">website</a>.
                  </small></p>

                </section>
              </div>
